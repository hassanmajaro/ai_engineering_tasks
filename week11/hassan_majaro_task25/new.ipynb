{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52c31f3f",
   "metadata": {},
   "source": [
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c2562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Keep raw frames from EDA\n",
    "# train_df, test_df already exist (untouched)\n",
    "\n",
    "# 2) Define target and drop ID\n",
    "TARGET = \"Loan_Status\"\n",
    "ID_COL = \"Loan_ID\"\n",
    "\n",
    "# 3) Split features/target from RAW (no edits)\n",
    "X_raw = train_df.drop(columns=[TARGET, ID_COL], errors=\"ignore\")\n",
    "y_raw = train_df[TARGET].map({'Y':1,'N':0})  # encode target only\n",
    "\n",
    "# 4) Identify column types from RAW (no editing)\n",
    "numeric_cols = X_raw.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = X_raw.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "numeric_cols, categorical_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1888ec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# 5) Train/validation split on RAW (still no edits to the raw frames)\n",
    "X_train_raw, X_val_raw, y_train, y_val = train_test_split(\n",
    "    X_raw, y_raw, test_size=0.2, random_state=42, stratify=y_raw\n",
    ")\n",
    "\n",
    "# 6) Column-wise preprocessing\n",
    "num_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_pipe, numeric_cols),\n",
    "        (\"cat\", cat_pipe, categorical_cols)\n",
    "    ],\n",
    "    remainder=\"drop\"  # drop anything unexpected\n",
    ")\n",
    "\n",
    "# 7) Example: make a modeling-ready matrix\n",
    "X_train = preprocess.fit_transform(X_train_raw)\n",
    "X_val   = preprocess.transform(X_val_raw)\n",
    "\n",
    "X_train.shape, X_val.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eda7a1b",
   "metadata": {},
   "source": [
    "baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfdd391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "\n",
    "def evaluate(name, y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\", zero_division=0)\n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"Accuracy: {acc:.3f}  Precision: {p:.3f}  Recall: {r:.3f}  F1: {f1:.3f}\")\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(classification_report(y_true, y_pred, digits=3))\n",
    "\n",
    "# 8) Logistic Regression (good, interpretable baseline)\n",
    "logit = Pipeline(steps=[\n",
    "    (\"pre\", preprocess),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, class_weight=\"balanced\"))\n",
    "])\n",
    "logit.fit(X_train_raw, y_train)\n",
    "y_pred_lr = logit.predict(X_val_raw)\n",
    "evaluate(\"Logistic Regression\", y_val, y_pred_lr)\n",
    "\n",
    "# 9) Random Forest (often stronger out-of-the-box)\n",
    "rf = Pipeline(steps=[\n",
    "    (\"pre\", preprocess),\n",
    "    (\"clf\", RandomForestClassifier(\n",
    "        n_estimators=300, max_depth=None, random_state=42, class_weight=\"balanced\"\n",
    "    ))\n",
    "])\n",
    "rf.fit(X_train_raw, y_train)\n",
    "y_pred_rf = rf.predict(X_val_raw)\n",
    "evaluate(\"Random Forest\", y_val, y_pred_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39c6595",
   "metadata": {},
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5ed735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build test feature frame from RAW test_df\n",
    "X_test_raw = test_df.drop(columns=[ID_COL], errors=\"ignore\")\n",
    "\n",
    "# Use your best pipeline (e.g., rf) to generate predictions\n",
    "test_pred = rf.predict(X_test_raw)                 # 0/1 labels\n",
    "test_pred_proba = rf.predict_proba(X_test_raw)[:,1]  # approval probability\n",
    "\n",
    "# If you want a submission-style frame:\n",
    "out = pd.DataFrame({\n",
    "    ID_COL: test_df[ID_COL],\n",
    "    \"Loan_Status_Pred\": np.where(test_pred==1, \"Y\", \"N\"),\n",
    "    \"Approval_Prob\": test_pred_proba\n",
    "})\n",
    "out.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f851f03b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
