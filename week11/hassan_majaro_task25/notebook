{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⚙️ Home Loan — Preprocessing & Baseline Modeling\n",
    "\n",
    "This notebook performs **model-ready preprocessing** (imputation, encoding, scaling) and trains **baseline models**\n",
    "(Logistic Regression, Decision Tree, Random Forest) on the Home Loan dataset.\n",
    "\n",
    "**Data Source:**\n",
    "- Train: https://raw.githubusercontent.com/ek-chris/Practice_datasets/refs/heads/main/home_loan_train.csv\n",
    "- Test:  https://raw.githubusercontent.com/ek-chris/Practice_datasets/refs/heads/main/home_loan_test.csv\n",
    "\n",
    "> Note: EDA stays in a separate notebook. Here, we transform raw data into a modeling matrix using sklearn pipelines.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid', palette='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_url = 'https://raw.githubusercontent.com/ek-chris/Practice_datasets/refs/heads/main/home_loan_train.csv'\n",
    "test_url  = 'https://raw.githubusercontent.com/ek-chris/Practice_datasets/refs/heads/main/home_loan_test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_url)\n",
    "test_df  = pd.read_csv(test_url)\n",
    "\n",
    "print('Train shape:', train_df.shape)\n",
    "print('Test shape :', test_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Define Features & Target (RAW)\n",
    "We do **not** clean the raw frames manually. All preprocessing lives in sklearn pipelines to avoid leakage and keep things reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'Loan_Status'\n",
    "ID_COL = 'Loan_ID'\n",
    "\n",
    "# Features/Target from raw\n",
    "X_raw = train_df.drop(columns=[TARGET, ID_COL], errors='ignore')\n",
    "y_raw = train_df[TARGET].map({'Y':1, 'N':0})  # encode target only\n",
    "\n",
    "print('X_raw shape:', X_raw.shape)\n",
    "print('y_raw distribution:\\n', y_raw.value_counts(normalize=True).round(3))\n",
    "\n",
    "# Identify column types from RAW\n",
    "numeric_cols = X_raw.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = X_raw.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "numeric_cols, categorical_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Train/Validation Split (on RAW)\n",
    "We split first, then fit the preprocessing only on the training fold to avoid leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw, X_val_raw, y_train, y_val = train_test_split(\n",
    "    X_raw, y_raw, test_size=0.2, random_state=42, stratify=y_raw\n",
    ")\n",
    "X_train_raw.shape, X_val_raw.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Preprocessing Pipelines (No manual edits)\n",
    "- **Numeric:** median imputation → StandardScaler\n",
    "- **Categorical:** most_frequent imputation → OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "All transformations are fit on the training fold only and then applied to validation/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipe = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(transformers=[\n",
    "    ('num', num_pipe, numeric_cols),\n",
    "    ('cat', cat_pipe, categorical_cols)\n",
    "])\n",
    "preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Helper: Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    print(f\"\\n{name} Results\")\n",
    "    print('-'*40)\n",
    "    print(f\"Accuracy : {acc:.3f}\")\n",
    "    print(f\"Precision: {prec:.3f}\")\n",
    "    print(f\"Recall   : {rec:.3f}\")\n",
    "    print(f\"F1-score : {f1:.3f}\")\n",
    "    print('\\nConfusion Matrix:\\n', confusion_matrix(y_true, y_pred))\n",
    "    print('\\nClassification Report:\\n', classification_report(y_true, y_pred, digits=3))\n",
    "    return {'Accuracy': acc, 'Precision': prec, 'Recall': rec, 'F1': f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Baseline Models (Pipelines)\n",
    "Each model is wrapped in a Pipeline with the shared `preprocess` step to ensure identical transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'Logistic Regression': Pipeline(steps=[\n",
    "        ('pre', preprocess),\n",
    "        ('clf', LogisticRegression(max_iter=2000, class_weight='balanced'))\n",
    "    ]),\n",
    "    'Decision Tree': Pipeline(steps=[\n",
    "        ('pre', preprocess),\n",
    "        ('clf', DecisionTreeClassifier(max_depth=4, random_state=42))\n",
    "    ]),\n",
    "    'Random Forest': Pipeline(steps=[\n",
    "        ('pre', preprocess),\n",
    "        ('clf', RandomForestClassifier(n_estimators=300, random_state=42, class_weight='balanced'))\n",
    "    ])\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, pipe in pipelines.items():\n",
    "    pipe.fit(X_train_raw, y_train)\n",
    "    y_pred = pipe.predict(X_val_raw)\n",
    "    results[name] = evaluate_model(name, y_val, y_pred)\n",
    "\n",
    "pd.DataFrame(results).T.sort_values('F1', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Cross-Validation (Optional Quick Check)\n",
    "Fast 5-fold CV on the best candidate (Random Forest by default here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv = Pipeline(steps=[('pre', preprocess), ('clf', RandomForestClassifier(n_estimators=300, random_state=42, class_weight='balanced'))])\n",
    "scores = cross_val_score(rf_cv, X_raw, y_raw, cv=5, scoring='f1')\n",
    "print('5-fold F1 mean:', scores.mean().round(3), '±', scores.std().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Feature Importance (Random Forest)\n",
    "We fit a fresh RF pipeline, then extract OHE feature names to align importances with columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe = Pipeline(steps=[\n",
    "    ('pre', preprocess),\n",
    "    ('clf', RandomForestClassifier(n_estimators=300, random_state=42, class_weight='balanced'))\n",
    "])\n",
    "rf_pipe.fit(X_train_raw, y_train)\n",
    "\n",
    "# Extract feature names from the fitted preprocessor\n",
    "pre_fitted = rf_pipe.named_steps['pre']\n",
    "\n",
    "num_names = numeric_cols\n",
    "ohe = pre_fitted.named_transformers_['cat'].named_steps['ohe']\n",
    "cat_names = ohe.get_feature_names_out(categorical_cols).tolist()\n",
    "feature_names = num_names + cat_names\n",
    "\n",
    "importances = rf_pipe.named_steps['clf'].feature_importances_\n",
    "feat_imp = pd.Series(importances, index=feature_names).sort_values(ascending=False).head(15)\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "sns.barplot(x=feat_imp.values, y=feat_imp.index)\n",
    "plt.title('Top 15 Feature Importances — Random Forest')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "feat_imp.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Predict on Test Set + Export Submission\n",
    "We apply the **same** fitted pipeline to the raw test frame. No manual cleaning on test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the best-performing pipeline (replace with your pick if different)\n",
    "best_pipe = rf_pipe  # Random Forest pipeline from above\n",
    "\n",
    "# Build test feature frame (drop ID only)\n",
    "X_test_raw = test_df.drop(columns=[ID_COL], errors='ignore')\n",
    "test_pred = best_pipe.predict(X_test_raw)\n",
    "test_proba = best_pipe.predict_proba(X_test_raw)[:, 1]\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    ID_COL: test_df[ID_COL],\n",
    "    'Loan_Status_Pred': np.where(test_pred==1, 'Y', 'N'),\n",
    "    'Approval_Prob': test_proba\n",
    "})\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) (Optional) Persist Trained Model\n",
    "Save the fitted pipeline (preprocessing + model) to disk for reuse/deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(best_pipe, 'loan_status_pipeline.pkl')\n",
    "print('Saved model to loan_status_pipeline.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
